

# Performance Benchmarks

### Load Test Results (NVIDIA A10G GPU)
| Concurrency | Avg Latency (s) | P95 Latency (s) | Error Rate (%) |
|-------------|----------------|----------------|----------------|
| 4           | 0.61          | 0.00          | 0.0           |
| 8           | 0.93          | 0.00          | 0.0           |
| 16          | 0.85          | 0.00          | 0.0           |
| 32          | 1.11          | 1.99          | 0.0           |
| 64          | 2.38          | 4.20          | 0.0           |
| 128         | 4.31          | 8.03          | 0.0           |
| 192         | 6.87          | 12.88         | 0.0           |
| 256         | 9.04          | 16.88         | 0.0           |
| 512         | 17.63         | 33.19         | 0.0           |


----------------------------------------------
----------------------------------------------
2024-11-24

Concurrency Avg Latency  P95 Latency  Error Rate
--------------------------------------------
4          0.50........ 0.00........ 0.0.......%
8          0.52........ 0.00........ 0.0.......%
16         0.84........ 0.00........ 0.0.......%
32         1.76........ 2.33........ 0.0.......%
64         2.99........ 4.54........ 0.0.......%
128        5.37........ 8.92........ 0.0.......%
192        7.60........ 12.55....... 0.0.......%
256        9.52........ 16.80....... 0.0.......%
512        17.89....... 33.23....... 0.0.......%


`serve_config.yaml`
```
proxy_location: EveryNode

http_options:
  host: 0.0.0.0
  port: 8000
  
applications:
- name: whisper_service
  route_prefix: /
  import_path: main:app
  runtime_env:
    pip:
      - torch
      - transformers
      - fastapi
      - python-multipart
  deployments:
  - name: WhisperTranscriber
    max_outgoing_requests: 25
    autoscaling_config:
      target_outgoing_requests: 10
      min_replicas: 8
      max_replicas: 25
      upscale_delay_s: 10
      downscale_delay_s: 30
      upscale_batch_size: 2  # Only addition: control scaling batch size
    ray_actor_options:
      num_cpus: 1
      num_gpus: 0.037
      memory: 2000_000_000
      runtime_env:
        env_vars:
          CUDA_VISIBLE_DEVICES: "0"
  - name: WhisperAPI
    max_outgoing_requests: 30
    autoscaling_config:
      target_outgoing_requests: 12
      min_replicas: 8
      max_replicas: 30
    ray_actor_options:
      num_cpus: 1
      memory: 2000_000_000
```

---

### cluster 8 GPU workers - whisper model base - audio 5 sec

```
  deployments:
  - name: WhisperTranscriber
    max_outgoing_requests: 1
    autoscaling_config:
      target_outgoing_requests: 25
      min_replicas: 8
      max_replicas: 60
    ray_actor_options:
      num_cpus: 1
      num_gpus: 0.25
  - name: WhisperAPI
    max_outgoing_requests: 1
    autoscaling_config:
      target_outgoing_requests: 25
      min_replicas: 8
      max_replicas: 40
    ray_actor_options:
      num_cpus: 1
```

Concurrency Avg Latency  P95 Latency  Error Rate
--------------------------------------------
4          0.55........ 0.00........ 0.0.......%
8          0.57........ 0.00........ 0.0.......%
16         0.63........ 0.00........ 0.0.......%
32         0.73........ 1.29........ 0.0.......%
64         1.03........ 1.78........ 0.0.......%
128        1.78........ 2.59........ 0.0.......%
192        2.49........ 4.02........ 0.0.......%
256        2.86........ 4.61........ 0.0.......%
512        4.98........ 8.45........ 0.0.......%

Concurrency Avg Latency  P95 Latency  Error Rate
--------------------------------------------
4          0.49........ 0.00........ 0.0.......%
8          0.54........ 0.00........ 0.0.......%
16         0.59........ 0.00........ 0.0.......%
32         0.70........ 1.20........ 0.0.......%
64         1.08........ 1.86........ 0.0.......%
128        1.76........ 2.78........ 0.0.......%
192        2.28........ 3.54........ 0.0.......%
256        2.82........ 4.49........ 0.0.......%
512        4.86........ 8.60........ 0.0.......%


---
2024-11-29


### cluster 8 GPU workers - whisper model large - audio 5 sec

Starting load test...
Concurrency Avg Latency  P95 Latency  Error Rate
--------------------------------------------
4          0.54........ 0.00........ 0.0.......%
8          0.56........ 0.00........ 0.0.......%
16         0.66........ 0.00........ 0.0.......%
32         1.00........ 1.71........ 0.0.......%
64         1.70........ 2.69........ 0.0.......%
128        1.73........ 2.74........ 0.0.......%
192        2.37........ 3.68........ 0.0.......%
256        2.60........ 4.24........ 0.0.......%
512        4.66........ 7.97........ 0.0.......%

(venv-3.9) marco@genai:~/Development/mglabs/stt-server$ python ./tests/load_test.py 

Starting load test...
Concurrency Avg Latency  P95 Latency  Error Rate
--------------------------------------------
4          0.49........ 0.00........ 0.0.......%
8          0.73........ 0.00........ 0.0.......%
16         0.59........ 0.00........ 0.0.......%
32         0.73........ 1.23........ 0.0.......%
64         1.04........ 1.96........ 0.0.......%
128        1.66........ 2.50........ 0.0.......%
192        2.26........ 3.70........ 0.0.......%
256        2.60........ 4.31........ 0.0.......%
512        4.68........ 8.01........ 0.0.......%
