{
    "server": {
        "host": "0.0.0.0",
        "port": 8000,
        "dedicated_cpu": true,
        "num_cpus": 24
    },
    "model": {
        "size": "base",
        "device": "cuda",
        "model_dir": "models",
        "supported_formats": [".wav", ".mp3", ".m4a", ".ogg"]
    },
    "deployment": {
        "num_replicas": 16,
        "cpu_per_replica": 1.0,
        "gpu_per_replica": 0.0625,
        "max_concurrent_queries": 64
    },
    "logging": {
        "level": "INFO",
        "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        "file": "whisper_service.log"
    }
}