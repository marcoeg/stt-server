

# Performance Benchmarks

### Load Test Results (NVIDIA A10G GPU)
| Concurrency | Avg Latency (s) | P95 Latency (s) | Error Rate (%) |
|-------------|----------------|----------------|----------------|
| 4           | 0.61          | 0.00          | 0.0           |
| 8           | 0.93          | 0.00          | 0.0           |
| 16          | 0.85          | 0.00          | 0.0           |
| 32          | 1.11          | 1.99          | 0.0           |
| 64          | 2.38          | 4.20          | 0.0           |
| 128         | 4.31          | 8.03          | 0.0           |
| 192         | 6.87          | 12.88         | 0.0           |
| 256         | 9.04          | 16.88         | 0.0           |
| 512         | 17.63         | 33.19         | 0.0           |


----------------------------------------------
----------------------------------------------
2024-11-24

Concurrency Avg Latency  P95 Latency  Error Rate
--------------------------------------------
4          0.50........ 0.00........ 0.0.......%
8          0.52........ 0.00........ 0.0.......%
16         0.84........ 0.00........ 0.0.......%
32         1.76........ 2.33........ 0.0.......%
64         2.99........ 4.54........ 0.0.......%
128        5.37........ 8.92........ 0.0.......%
192        7.60........ 12.55....... 0.0.......%
256        9.52........ 16.80....... 0.0.......%
512        17.89....... 33.23....... 0.0.......%


`serve_config.yaml`
```
proxy_location: EveryNode

http_options:
  host: 0.0.0.0
  port: 8000
  
applications:
- name: whisper_service
  route_prefix: /
  import_path: main:app
  runtime_env:
    pip:
      - torch
      - transformers
      - fastapi
      - python-multipart
  deployments:
  - name: WhisperTranscriber
    max_outgoing_requests: 25
    autoscaling_config:
      target_outgoing_requests: 10
      min_replicas: 8
      max_replicas: 25
      upscale_delay_s: 10
      downscale_delay_s: 30
      upscale_batch_size: 2  # Only addition: control scaling batch size
    ray_actor_options:
      num_cpus: 1
      num_gpus: 0.037
      memory: 2000_000_000
      runtime_env:
        env_vars:
          CUDA_VISIBLE_DEVICES: "0"
  - name: WhisperAPI
    max_outgoing_requests: 30
    autoscaling_config:
      target_outgoing_requests: 12
      min_replicas: 8
      max_replicas: 30
    ray_actor_options:
      num_cpus: 1
      memory: 2000_000_000
```

---

### cluster 8 GPU workers - whisper model base - audio 5 sec

```
  deployments:
  - name: WhisperTranscriber
    max_outgoing_requests: 1
    autoscaling_config:
      target_outgoing_requests: 25
      min_replicas: 8
      max_replicas: 60
    ray_actor_options:
      num_cpus: 1
      num_gpus: 0.25
  - name: WhisperAPI
    max_outgoing_requests: 1
    autoscaling_config:
      target_outgoing_requests: 25
      min_replicas: 8
      max_replicas: 40
    ray_actor_options:
      num_cpus: 1
```

Concurrency Avg Latency  P95 Latency  Error Rate
--------------------------------------------
4          0.55........ 0.00........ 0.0.......%
8          0.57........ 0.00........ 0.0.......%
16         0.63........ 0.00........ 0.0.......%
32         0.73........ 1.29........ 0.0.......%
64         1.03........ 1.78........ 0.0.......%
128        1.78........ 2.59........ 0.0.......%
192        2.49........ 4.02........ 0.0.......%
256        2.86........ 4.61........ 0.0.......%
512        4.98........ 8.45........ 0.0.......%

Concurrency Avg Latency  P95 Latency  Error Rate
--------------------------------------------
4          0.49........ 0.00........ 0.0.......%
8          0.54........ 0.00........ 0.0.......%
16         0.59........ 0.00........ 0.0.......%
32         0.70........ 1.20........ 0.0.......%
64         1.08........ 1.86........ 0.0.......%
128        1.76........ 2.78........ 0.0.......%
192        2.28........ 3.54........ 0.0.......%
256        2.82........ 4.49........ 0.0.......%
512        4.86........ 8.60........ 0.0.......%


---
2024-11-29


### cluster 8 GPU workers - whisper model large - audio 5 sec

Starting load test...
Concurrency Avg Latency  P95 Latency  Error Rate
--------------------------------------------
4          0.54........ 0.00........ 0.0.......%
8          0.56........ 0.00........ 0.0.......%
16         0.66........ 0.00........ 0.0.......%
32         1.00........ 1.71........ 0.0.......%
64         1.70........ 2.69........ 0.0.......%
128        1.73........ 2.74........ 0.0.......%
192        2.37........ 3.68........ 0.0.......%
256        2.60........ 4.24........ 0.0.......%
512        4.66........ 7.97........ 0.0.......%

(venv-3.9) marco@genai:~/Development/mglabs/stt-server$ python ./tests/load_test.py 

Starting load test...
Concurrency Avg Latency  P95 Latency  Error Rate
--------------------------------------------
4          0.49........ 0.00........ 0.0.......%
8          0.73........ 0.00........ 0.0.......%
16         0.59........ 0.00........ 0.0.......%
32         0.73........ 1.23........ 0.0.......%
64         1.04........ 1.96........ 0.0.......%
128        1.66........ 2.50........ 0.0.......%
192        2.26........ 3.70........ 0.0.......%
256        2.60........ 4.31........ 0.0.......%
512        4.68........ 8.01........ 0.0.......%


----------- Modal deployment

GPU=t4
Starting load test for model_size=base, language=en
Concurrency Avg Latency  P95 Latency  Error Rate
--------------------------------------------
4          1.10........ 0.00........ 0.0.......%
8          1.11........ 0.00........ 0.0.......%
16         1.28........ 0.00........ 0.0.......%
32         1.54........ 2.23........ 0.0.......%
64         2.21........ 3.53........ 0.0.......%
128        3.57........ 5.93........ 0.0.......%
192        4.91........ 8.48........ 0.0.......%
256        6.22........ 10.99....... 0.0.......%
512        11.57....... 20.99....... 0.0.......%

gpu=A10G
Starting load test for model_size=base, language=en
Concurrency Avg Latency  P95 Latency  Error Rate
--------------------------------------------
4          0.89........ 0.00........ 0.0.......%
8          1.02........ 0.00........ 0.0.......%
16         1.32........ 0.00........ 0.0.......%
32         1.88........ 3.03........ 0.0.......%
64         3.14........ 5.26........ 0.0.......%
128        5.35........ 9.57........ 0.0.......%
192        7.68........ 13.91....... 0.0.......%
256        9.76........ 17.86....... 0.0.......%
512        19.17....... 35.47....... 0.0.......%

gpu=modal.gpu.H100
Starting load test for model_size=base, language=en
Concurrency Avg Latency  P95 Latency  Error Rate
--------------------------------------------
4          0.94........ 0.00........ 0.0.......%
8          1.04........ 0.00........ 0.0.......%
16         1.32........ 0.00........ 0.0.......%
32         1.86........ 2.89........ 0.0.......%
64         3.01........ 4.97........ 0.0.......%
128        5.36........ 9.51........ 0.0.......%
192        7.38........ 13.24....... 0.0.......%
256        9.65........ 17.57....... 0.0.......%
512        18.53....... 34.47....... 0.0.......%


gpu=H100
Starting load test for model_size=base, language=en
Concurrency Avg Latency  P95 Latency  Error Rate
--------------------------------------------
4          0.88........ 0.00........ 0.0.......%
8          0.99........ 0.00........ 0.0.......%
16         1.23........ 0.00........ 0.0.......%
32         1.70........ 2.61........ 0.0.......%
64         2.63........ 4.32........ 0.0.......%
128        4.51........ 7.82........ 0.0.......%
192        6.65........ 11.80....... 0.0.......%
256        8.36........ 15.04....... 0.0.......%
512        15.53....... 28.65....... 0.0.......%

gpu=A10G/H100
Starting load test for model_size=base, language=en
Concurrency Avg Latency  P95 Latency  Error Rate
--------------------------------------------
4          1.14........ 0.00........ 0.0.......%
8          1.45........ 0.00........ 0.0.......%
16         1.99........ 0.00........ 0.0.......%
32         3.14........ 5.31........ 0.0.......%
64         5.04........ 8.83........ 0.0.......%
128        7.53........ 12.60....... 0.0.......%
192        8.25........ 14.94....... 0.5.......%
256        10.68....... 19.47....... 0.0.......%
512        20.88....... 38.81....... 0.0.......%

-- optimized

gpu=A10G
Starting load test for model_size=base, language=en
Concurrency Avg Latency  P95 Latency  Error Rate
--------------------------------------------
4          1.11........ 0.00........ 0.0.......%
8          1.30........ 0.00........ 0.0.......%
16         1.77........ 0.00........ 0.0.......%
32         2.85........ 4.68........ 0.0.......%
64         4.50........ 7.84........ 0.0.......%
128        8.15........ 14.67....... 0.0.......%
192        12.17....... 22.16....... 0.0.......%
256        16.05....... 29.43....... 0.0.......%
512        36.59....... 68.49....... 0.0.......%


Starting load test for model_size=large, language=en
Concurrency Avg Latency  P95 Latency  Error Rate
--------------------------------------------
4          2.67........ 0.00........ 0.0.......%
8          3.68........ 0.00........ 0.0.......%
16         6.16........ 0.00........ 0.0.......%
32         9.77........ 17.04....... 0.0.......%
64         16.72....... 30.88....... 0.0.......%
